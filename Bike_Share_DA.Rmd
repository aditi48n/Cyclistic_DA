---
title: "Bike Share DA"
author: "Aditi Nagaraj Nallan"
date: "2023-10-18"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the required R packages 

```{r load packages}
suppressPackageStartupMessages(library(tidyverse))
library(lubridate)
library(MetBrewer)
```

##Initial exploration of rider data for September, 2023

Load the September dataset and check for the structure and datatype:

```{r pressure, echo=FALSE}
September_data = read_csv("2023/202309-divvy-tripdata.csv")
```

Now, check for the number rows and columns in the data and inspect other data attributes

```{r}
colnames(September_data)
dim(September_data)
str(September_data)
```

From the output above we see that, there are a total of 666371 rows and 13 columns. Of these 13, 7 are type character and 4 are type double. Let's now ensure that the two columns **started_at** and **ended_at** are date_time type to correctly represent the contents of the column. 

```{r}
September_data$started_at = lubridate::as_datetime(September_data$started_at)
September_data$ended_at = lubridate::as_datetime(September_data$ended_at)

#Check to see if the column type is correct
class(September_data$started_at)
class(September_data$ended_at)
```

In the next step, let us check for any missing values or duplicated ride ids in the data and count how many of these are present!

```{r}
colSums(is.na(September_data))
sum(duplicated(September_data$ride_id))
```

From the output above we see that there are no duplicated values. As for the missing values, 6 columns contain missing values. However, four of these columns are irrelevant to our analysis and will thus be dropped in the subsequent section. The other two columns (**start_station_name** and **end_station_name**) will be retained with missing data to ensure that we don't statistically skew the data. These columns will be later used to understand which bike pick up and drop off points are most popular in the city among casual users and members. 

```{r}
#Let us drop the unwanted columns:
September_data = subset(September_data, select = -c(start_station_id, end_station_id, start_lat, start_lng, end_lat, end_lng))
```

Let us now use the two columns **started_at** and **ended_at** to calculate **ride_length** and add this new column to the dataframe. 

```{r}
ride_length = as.numeric(difftime(September_data$ended_at,September_data$started_at, units = "secs"))
September_data$ride_duration = sprintf("%02d:%02d:%02d",
                                    ride_length %/% 3600,
                                    (ride_length %% 3600) %/% 60,
                                    ride_length %% 60)
```

Let us also find the **day_of_week** these rides were booked and add this new column to the dataframe:

```{r}
September_data$day_of_week = wday(September_data$started_at,label = TRUE)
```

Finally, let us extract ride duration in minutes to perform calculations and add the new column **ride_duration_minutes** to the dataframe. 
```{r}
#First write a function to convert the HH:MM:SS format and extract total minutes: 
hhmmss_to_minutes = function(time_string) {
  parts = unlist(strsplit(time_string, ":"))
  if (length(parts) == 3) {
    hours = as.numeric(parts[1])
    minutes = as.numeric(parts[2])
    seconds = as.numeric(parts[3])
    total_minutes = (hours * 60) + minutes + (seconds / 60)
    return(total_minutes)
  } else {
    return(NA)
  }
}

# Apply the conversion function to the ride_duration column
September_data$ride_duration_minutes = sapply(September_data$ride_duration, hhmmss_to_minutes)
```

We see that there are some ride duration with negative values. Let us first start by removing them as these correspond to the time when bikes were taken out from the docks for routine checking:

```{r}
September_data = September_data[!(September_data$ride_duration_minutes<0),]
```

##Descriptive Analysis

Now that we have appropriately prepared the data for analysis, let us conduct a descriptive analysis:

```{r descriptive analysis}
summary(September_data$ride_duration_minutes)
```

We see that the mean ride duration was around 18 minutes! 
Let us now compare the mean ride duration between the members and casual users:
```{r}
aggregate(September_data$ride_duration_minutes ~ September_data$member_casual, FUN= mean)
```
From the table above we see that casual users tend to ride the bikes longer than Cyclistic members. Let us also see the average ride times by each day for members versus casual users:
```{r}
aggregate(September_data$ride_duration_minutes ~September_data$member_casual + September_data$day_of_week, FUN=mean)
```
From the table above we see that on an average, casual users tend to ride the bikes longer than Cyclistic members on any given day. 

Next let's analyse ridership data by type and weekday:
```{r}
September_data %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  
  group_by(member_casual, weekday) %>%  
  summarise(number_of_rides = n()							
  ,average_duration = mean(ride_duration_minutes)) %>% 		
  arrange(member_casual, weekday)								
```

From the summary table we see that Saturday had the highest number of rides booked in the month of September. The average ride duration was also highest on Saturday and Sunday compared to the weekdays. 

Now that we have looked at one month's trend, let us extrapolate our analysis to all months in the year 2023 and see how these trends vary across different months- 

##Expansion of analysis across multiple months

###Step 1: Data Collection


```{r load datasets}
#Load datasets for each month and store it in the corresponding variable
January_data = read_csv("2023/202301-divvy-tripdata.csv")
February_data = read_csv("2023/202302-divvy-tripdata.csv")
March_data = read_csv("2023/202303-divvy-tripdata.csv")
April_data = read_csv("2023/202304-divvy-tripdata.csv")
May_data = read_csv("2023/202305-divvy-tripdata.csv")
June_data = read_csv("2023/202306-divvy-tripdata.csv")
July_data = read_csv("2023/202307-divvy-tripdata.csv")
August_data = read_csv("2023/202308-divvy-tripdata.csv")
September_data = read_csv("2023/202309-divvy-tripdata.csv")
```

###Step 2: Data Wrangling

```{r}
#Merge the datasets into one large dataframe and inspect the newly created table 
all_trips <- bind_rows(January_data, February_data, March_data, April_data, May_data, June_data, July_data, August_data, September_data, .id = "month")
dim(all_trips)
str(all_trips)
```

From the output above we see that, there are a total of 4596173 rows and 14 columns. Of these 14, 7 are type character and 4 are type double. Let's now ensure that the two columns **started_at** and **ended_at** are date_time type to correctly represent the contents of the column. 

```{r}
all_trips$started_at = lubridate::as_datetime(all_trips$started_at)
all_trips$ended_at = lubridate::as_datetime(all_trips$ended_at)
```

###Step 3: Data preparation for analysis

```{r}
#Let us drop the unwanted columns:
all_trips = subset(all_trips, select = -c(start_station_id, end_station_id, start_lat, start_lng, end_lat, end_lng))
```

Let us now use the two columns **started_at** and **ended_at** to calculate **ride_length** and add this new column to the dataframe. 

```{r}
ride_length = as.numeric(difftime(all_trips$ended_at,all_trips$started_at, units = "secs"))
all_trips$ride_duration = sprintf("%02d:%02d:%02d",
                                    ride_length %/% 3600,
                                    (ride_length %% 3600) %/% 60,
                                    ride_length %% 60)
```

Let us also find the **day_of_week** these rides were booked and add this new column to the dataframe:

```{r}
all_trips$day_of_week = wday(all_trips$started_at,label = TRUE)
```

Finally, let us extract ride duration in minutes to perform calculations and add the new column **ride_duration_minutes** to the dataframe. 
```{r}
# Apply the conversion function to the ride_duration column in the new table
all_trips$ride_duration_minutes = sapply(all_trips$ride_duration, hhmmss_to_minutes)
```

We see that there are some ride duration with negative values. Let us first start by removing them as these correspond to the time when bikes were taken out from the docks for routine checking:

```{r}
all_trips = all_trips[!(all_trips$ride_duration_minutes<0),]
```

We see that the month column is populated by integers. Let us fix this by substituting the month name for the appropriate integer:

```{r}
all_trips$month <- factor(all_trips$month,
                          levels = 1:9,  # Assuming that your data includes months January through September
                          labels = c("January", "February", "March", "April", "May", "June", "July", "August", "September"))
```

###Step 4: Data Visualization and Insights

Previously, we performed descriptive analysis to see the trends in data for the month of September. Lets now visualize some of these trends in the newly created data table:

**The number of rides by month**

```{r}
# Group by month, possibly also by user type if you want that level of detail
monthly_rides <- all_trips %>%
  group_by(month, member_casual) %>%
  summarise(count = n(), .groups = 'drop')

# Now, create a plot to visualize monthly trends
ggplot(monthly_rides, aes(x = month, y = count, fill = member_casual)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Monthly bike usage", x = "Month", y = "Number of Rides") +
  scale_fill_manual(values=met.brewer("Juarez", 2), name = "User Type") +
  theme_minimal()
```
From the plot we see that the bike usage among members and casual users is increased from January to September, with the months of July and August showing the highest usage. It can also be seen that casual users did not avail bike service during the winter months of January, February and March. Let us add another layer to it and see how bike usage differs across the different days of the week for each month. 

**The number of rides by rider type and day of the week**

```{r viz1}
ggplot(all_trips, aes(x = day_of_week, fill = member_casual)) +
                    geom_bar(position = position_dodge()) +
                    labs(title = "Usage counts by User type and Day of the Week", x = "Day of the Week", y = "Count") +
                    scale_fill_manual(values=met.brewer("Juarez", 2), name = "User Type") + 
                    theme_minimal() + 
                    facet_wrap(~month) +
                    theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

From the bar plot above we see that generally members tend to use the bike share platform more during the week compared to non-members. Non-members use the bike share platform more during the weekends almost matching the member usage, with highest usage recorded on Saturdays.

Now let's see how members and non-members compare in their ride duration:

```{r}
#Calculate total duration in minutes per day
trips_summary = all_trips %>%
  group_by(day_of_week, member_casual) %>%
  summarise(total_duration = mean(ride_duration_minutes, na.rm = TRUE), .groups = 'drop')
```

**Duration of rides by rider type**

```{r}
ggplot(trips_summary, aes(x = member_casual, y = total_duration, fill = day_of_week)) +
  geom_bar(stat = "identity", position = "dodge") +  
  labs(title = "Usage duration by user type", x = "User Type", y = "Average ride duration in minutes") +
  scale_fill_manual(values=met.brewer("Hiroshige", 7), name = "Day of the Week") + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  facet_grid(cols = vars(day_of_week)) +
  theme(panel.border = element_rect(colour = "grey", fill=NA))
```

From the grouped bar chart we see that the average ride duration is higher for non-members across all days of the week.

The patterns in the two plots indicate that Cyclistic members tend to use bikes consistently everyday as compared to casual customer who are more interested in using the bikes on weekends. Additionally, non-members (casual customers) tend to spend more time riding the bikes. This suggests that casual users might be travelling longer distances while members might be using bikes for commute from point A to point B only.

Let us now look at the hourly bike usage and compare it between members and non-members:

```{r}
#First extract the hour from start time:
all_trips$start_hour = lubridate::hour(all_trips$started_at)

#Count the number of rides per hour grouped by user type
hourly_rides = all_trips %>%
  group_by(start_hour, member_casual) %>%
  summarise(count = n(), .groups = 'drop')
```

**Hourly bike usage**

```{r}
custom_hour_labels = c("12:00 AM", "4:00 AM", "8:00 AM", "12:00 PM", "4:00 PM", "8:00 PM")

ggplot(hourly_rides, aes(x = start_hour, y = count, color = member_casual)) +
  geom_line() +
  labs(title = "Hourly bike usage", x = "Hour of the Day", y = "Number of Rides") +
  scale_color_manual(values=met.brewer("Juarez", 2), name = "User Type") +
  theme_minimal() + 
  scale_x_continuous(
    breaks = seq(0, 23, by = 4),  
    labels = custom_hour_labels)
```

From the line plot we see that members tend to use the bike service typically during rush hours that is around 8:00 AM in the morning and 4:30PM in the evening! Non-members tend to use the bike more during the later part of the day.

Let us now compare this trends across weekdays and weekends. 

**Hourly bike usage based on day type**

```{r}
#Categorize days into 'Weekday' and 'Weekend'
all_trips$day_type = ifelse(weekdays(as.Date(all_trips$started_at)) %in% c('Saturday', 'Sunday'), 'Weekend', 'Weekday')

#Group by the new category and summarize
daily_rides = all_trips %>%
  group_by(day_type, start_hour, member_casual) %>%
  summarise(count = n(), .groups = 'drop')

custom_hour_labels = c("12:00 AM", "4:00 AM", "8:00 AM", "12:00 PM", "4:00 PM", "8:00 PM")

#Line Plot
ggplot(daily_rides, aes(x = start_hour, y = count, color = member_casual)) +
  geom_line() +
  facet_wrap(~ day_type) + 
  labs(title = "Hourly bike usage based on day type", x = "Hour of the day", y = "Number of rides") +
  scale_color_manual(values=met.brewer("Juarez", 2), name = "User Type") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  theme(panel.border = element_rect(colour = "black", fill=NA)) +
  scale_x_continuous(
    breaks = seq(0, 23, by = 4),  
    labels = custom_hour_labels)

```

From the plot above we see that bike usage trends on the weekends are similar for both members and casual users. 